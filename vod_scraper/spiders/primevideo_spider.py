import scrapy
import json
from pathlib import Path
from vod_scraper.items import VodScraperItem

class PrimevideoSpider(scrapy.Spider):
    name = "primevideo_spider"
    allowed_domains = ["amazon.co.jp"]
    start_urls = ["https://www.amazon.co.jp/dp/B08271NYW7"]

    def parse(self, response, **kwargs):
        slug = "joker-2019"
        title = "ã‚¸ãƒ§ãƒ¼ã‚«ãƒ¼"
        output_path = Path("outputs/vod_summary.json")

        # ã™ã§ã«JSONã«ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆã€ã‚¹ã‚­ãƒƒãƒ—
        if output_path.exists():
            try:
                with output_path.open(encoding="utf-8") as f:
                    existing_data = json.load(f)
                    if slug in existing_data and existing_data[slug].get("primevideo", {}).get("url"):
                        self.logger.info(f"ğŸŸ¢ Skipping Prime Video crawl for {title} (already in JSON)")
                        return
            except Exception as e:
                self.logger.warning(f"âš ï¸ Failed to read existing JSON: {e}")

        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ã§åˆ¤å®š
        if 200 <= response.status < 400:
            service = "rental"
            price = 400
        else:
            service = "disable"
            price = None

        yield VodScraperItem(
            slug=slug,
            title=title,
            url=response.url,
            service=service,
            price=price,
        )
