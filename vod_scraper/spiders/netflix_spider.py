import scrapy
import json
from pathlib import Path
from vod_scraper.items import VodScraperItem

class NetflixSpider(scrapy.Spider):
    name = "netflix_spider"
    allowed_domains = ["netflix.com"]
    start_urls = ["https://www.netflix.com/jp/title/81092221"]

    def parse(self, response, **kwargs):
        slug = "joker-2019"
        title = "ã‚¸ãƒ§ãƒ¼ã‚«ãƒ¼"
        output_path = Path("outputs/vod_summary.json")

        # ã™ã§ã«JSONã«ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆã€ã‚¹ã‚­ãƒƒãƒ—
        if output_path.exists():
            try:
                with output_path.open(encoding="utf-8") as f:
                    existing_data = json.load(f)
                    if slug in existing_data and existing_data[slug].get("netflix", {}).get("url"):
                        self.logger.info(f"ğŸŸ¢ Skipping Netflix crawl for {title} (already in JSON)")
                        return  # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’ã‚¹ã‚­ãƒƒãƒ—
            except Exception as e:
                self.logger.warning(f"âš ï¸ Failed to read existing JSON: {e}")

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã§åˆ¤å®š
        if 200 <= response.status < 400:
            service = "available"
            price = "free"
        else:
            service = "disable"
            price = None

        yield VodScraperItem(
            slug=slug,
            title=title,
            url=response.url,
            service=service,
            price=price,
        )
